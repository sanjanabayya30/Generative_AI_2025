{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzHPosQAIScPW8G7HENcYp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjanabayya30/Generative_AI_2025/blob/main/2019_W3_A3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl1yU2LaI1HG",
        "outputId": "777427b3-aedc-48d0-a6f6-9672f2963750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: x = 0.740, f(x) = 29.240\n",
            "Iteration 2: x = 0.615, f(x) = 25.978\n",
            "Iteration 3: x = 0.531, f(x) = 23.813\n",
            "Iteration 4: x = 0.469, f(x) = 22.204\n",
            "Iteration 5: x = 0.421, f(x) = 20.934\n",
            "Iteration 6: x = 0.380, f(x) = 19.891\n",
            "Iteration 7: x = 0.347, f(x) = 19.012\n",
            "Iteration 8: x = 0.317, f(x) = 18.254\n",
            "Iteration 9: x = 0.292, f(x) = 17.593\n",
            "Iteration 10: x = 0.270, f(x) = 17.008\n",
            "Iteration 11: x = 0.249, f(x) = 16.485\n",
            "Iteration 12: x = 0.231, f(x) = 16.016\n",
            "Iteration 13: x = 0.215, f(x) = 15.590\n",
            "Iteration 14: x = 0.200, f(x) = 15.203\n",
            "Iteration 15: x = 0.187, f(x) = 14.849\n",
            "Iteration 16: x = 0.174, f(x) = 14.525\n",
            "Iteration 17: x = 0.163, f(x) = 14.226\n",
            "Iteration 18: x = 0.152, f(x) = 13.950\n",
            "Iteration 19: x = 0.142, f(x) = 13.695\n",
            "Iteration 20: x = 0.133, f(x) = 13.458\n",
            "Iteration 21: x = 0.125, f(x) = 13.238\n",
            "Iteration 22: x = 0.117, f(x) = 13.034\n",
            "Iteration 23: x = 0.109, f(x) = 12.844\n",
            "Iteration 24: x = 0.103, f(x) = 12.666\n",
            "Iteration 25: x = 0.096, f(x) = 12.501\n",
            "Minimum value of x: 0.096\n"
          ]
        }
      ],
      "source": [
        "# Function and its derivative (gradient)\n",
        "def f(x):\n",
        "    return 5 * (x * 4) + 3 * (x * 2) + 10\n",
        "\n",
        "def f_prime(x):\n",
        "    return 20 * (x ** 3) + 6 * x\n",
        "\n",
        "# Gradient Descent Implementation\n",
        "def gradient_descent(learning_rate, initial_x, iterations):\n",
        "    x = initial_x\n",
        "    for i in range(iterations):\n",
        "        grad = f_prime(x)\n",
        "        x = x - learning_rate * grad\n",
        "        print(f\"Iteration {i+1}: x = {x:.3f}, f(x) = {f(x):.3f}\")\n",
        "    return x\n",
        "\n",
        "# Parameters\n",
        "initial_x = 1.0  # Starting point for x\n",
        "learning_rate = 0.01  # Step size\n",
        "iterations = 25  # Number of iterations\n",
        "\n",
        "# Run Gradient Descent\n",
        "min_x = gradient_descent(learning_rate, initial_x, iterations)\n",
        "print(f\"Minimum value of x: {min_x:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Define the function g(x, y) = 3x^2 + 5e^(-y) + 10\n",
        "def g(x, y):\n",
        "    return 3 * x**2 + 5 * math.exp(-y) + 10\n",
        "\n",
        "# Gradient of g(x, y) with respect to x and y\n",
        "def grad_g(x, y):\n",
        "    # Partial derivatives:\n",
        "    # ∂g/∂x = 6x\n",
        "    # ∂g/∂y = -5 * e^(-y)\n",
        "    grad_x = 6 * x\n",
        "    grad_y = -5 * math.exp(-y)\n",
        "    return grad_x, grad_y\n",
        "\n",
        "# Gradient Descent Algorithm to minimize g(x, y)\n",
        "def gradient_descent(learning_rate=0.01, initial_x=1.0, initial_y=1.0, num_iterations=100):\n",
        "    x = initial_x\n",
        "    y = initial_y\n",
        "\n",
        "    for iteration in range(num_iterations):\n",
        "        # Compute the gradient\n",
        "        grad_x, grad_y = grad_g(x, y)\n",
        "\n",
        "        # Update x and y based on the gradients\n",
        "        x = x - learning_rate * grad_x\n",
        "        y = y - learning_rate * grad_y\n",
        "\n",
        "        # Print progress at each iteration\n",
        "        print(f\"Iteration {iteration + 1}: x = {x:.3f}, y = {y:.3f}, g(x, y) = {g(x, y):.3f}\")\n",
        "\n",
        "    return x, y\n",
        "\n",
        "# Run Gradient Descent for exactly 100 iterations\n",
        "initial_x = 1.0  # Starting point for x\n",
        "initial_y = 1.0  # Starting point for y\n",
        "learning_rate = 0.01  # Learning rate\n",
        "num_iterations = 50  # Number of iterations\n",
        "\n",
        "# Find the values of x and y that minimize g(x, y)\n",
        "optimal_x, optimal_y = gradient_descent(learning_rate, initial_x, initial_y, num_iterations)\n",
        "\n",
        "# Print the result\n",
        "print(f\"\\nThe value of x that minimizes g(x, y) is: {optimal_x:.3f}\")\n",
        "print(f\"The value of y that minimizes g(x, y) is: {optimal_y:.3f}\")\n",
        "print(f\"The minimum value of g(x, y) is: {g(optimal_x, optimal_y):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ucpw6feJxPO",
        "outputId": "d875b11b-b505-408f-f84c-872a71d095ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: x = 0.940, y = 1.018, g(x, y) = 14.457\n",
            "Iteration 2: x = 0.884, y = 1.036, g(x, y) = 14.116\n",
            "Iteration 3: x = 0.831, y = 1.054, g(x, y) = 13.812\n",
            "Iteration 4: x = 0.781, y = 1.072, g(x, y) = 13.541\n",
            "Iteration 5: x = 0.734, y = 1.089, g(x, y) = 13.299\n",
            "Iteration 6: x = 0.690, y = 1.106, g(x, y) = 13.083\n",
            "Iteration 7: x = 0.648, y = 1.122, g(x, y) = 12.890\n",
            "Iteration 8: x = 0.610, y = 1.138, g(x, y) = 12.716\n",
            "Iteration 9: x = 0.573, y = 1.154, g(x, y) = 12.561\n",
            "Iteration 10: x = 0.539, y = 1.170, g(x, y) = 12.422\n",
            "Iteration 11: x = 0.506, y = 1.186, g(x, y) = 12.297\n",
            "Iteration 12: x = 0.476, y = 1.201, g(x, y) = 12.184\n",
            "Iteration 13: x = 0.447, y = 1.216, g(x, y) = 12.082\n",
            "Iteration 14: x = 0.421, y = 1.231, g(x, y) = 11.991\n",
            "Iteration 15: x = 0.395, y = 1.245, g(x, y) = 11.908\n",
            "Iteration 16: x = 0.372, y = 1.260, g(x, y) = 11.833\n",
            "Iteration 17: x = 0.349, y = 1.274, g(x, y) = 11.765\n",
            "Iteration 18: x = 0.328, y = 1.288, g(x, y) = 11.703\n",
            "Iteration 19: x = 0.309, y = 1.302, g(x, y) = 11.646\n",
            "Iteration 20: x = 0.290, y = 1.315, g(x, y) = 11.594\n",
            "Iteration 21: x = 0.273, y = 1.329, g(x, y) = 11.547\n",
            "Iteration 22: x = 0.256, y = 1.342, g(x, y) = 11.504\n",
            "Iteration 23: x = 0.241, y = 1.355, g(x, y) = 11.464\n",
            "Iteration 24: x = 0.227, y = 1.368, g(x, y) = 11.427\n",
            "Iteration 25: x = 0.213, y = 1.381, g(x, y) = 11.393\n",
            "Iteration 26: x = 0.200, y = 1.393, g(x, y) = 11.361\n",
            "Iteration 27: x = 0.188, y = 1.406, g(x, y) = 11.332\n",
            "Iteration 28: x = 0.177, y = 1.418, g(x, y) = 11.305\n",
            "Iteration 29: x = 0.166, y = 1.430, g(x, y) = 11.279\n",
            "Iteration 30: x = 0.156, y = 1.442, g(x, y) = 11.255\n",
            "Iteration 31: x = 0.147, y = 1.454, g(x, y) = 11.233\n",
            "Iteration 32: x = 0.138, y = 1.466, g(x, y) = 11.212\n",
            "Iteration 33: x = 0.130, y = 1.477, g(x, y) = 11.192\n",
            "Iteration 34: x = 0.122, y = 1.489, g(x, y) = 11.173\n",
            "Iteration 35: x = 0.115, y = 1.500, g(x, y) = 11.155\n",
            "Iteration 36: x = 0.108, y = 1.511, g(x, y) = 11.138\n",
            "Iteration 37: x = 0.101, y = 1.522, g(x, y) = 11.122\n",
            "Iteration 38: x = 0.095, y = 1.533, g(x, y) = 11.107\n",
            "Iteration 39: x = 0.090, y = 1.544, g(x, y) = 11.092\n",
            "Iteration 40: x = 0.084, y = 1.554, g(x, y) = 11.078\n",
            "Iteration 41: x = 0.079, y = 1.565, g(x, y) = 11.064\n",
            "Iteration 42: x = 0.074, y = 1.575, g(x, y) = 11.051\n",
            "Iteration 43: x = 0.070, y = 1.586, g(x, y) = 11.039\n",
            "Iteration 44: x = 0.066, y = 1.596, g(x, y) = 11.026\n",
            "Iteration 45: x = 0.062, y = 1.606, g(x, y) = 11.015\n",
            "Iteration 46: x = 0.058, y = 1.616, g(x, y) = 11.003\n",
            "Iteration 47: x = 0.055, y = 1.626, g(x, y) = 10.992\n",
            "Iteration 48: x = 0.051, y = 1.636, g(x, y) = 10.982\n",
            "Iteration 49: x = 0.048, y = 1.646, g(x, y) = 10.971\n",
            "Iteration 50: x = 0.045, y = 1.655, g(x, y) = 10.961\n",
            "\n",
            "The value of x that minimizes g(x, y) is: 0.045\n",
            "The value of y that minimizes g(x, y) is: 1.655\n",
            "The minimum value of g(x, y) is: 10.961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + math.exp(-x))\n",
        "\n",
        "def sigmoid_prime(x):\n",
        "    sx = sigmoid(x)\n",
        "    return sx * (1 - sx)\n",
        "\n",
        "def gradient_descent(learning_rate, max_iterations, initial_x):\n",
        "    x = initial_x\n",
        "    for _ in range(max_iterations):\n",
        "        x = x - learning_rate * sigmoid_prime(x)\n",
        "    return x\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.01\n",
        "max_iterations = 1000\n",
        "initial_x = 2.0\n",
        "\n",
        "# Find the minimum value of z(x)\n",
        "min_x = gradient_descent(learning_rate, max_iterations, initial_x)\n",
        "print(\"The value of x at which z(x) is minimized:\", min_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz0DLmZ9Kmr1",
        "outputId": "2a7fc190-65d8-4515-b063-fd408402f326"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of x at which z(x) is minimized: 0.3119424266221065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the model function\n",
        "def model(x, M, C):\n",
        "    return M * x + C\n",
        "\n",
        "# Derivative of the Squared Error with respect to M\n",
        "def dSE_dM(x, y, M, C):\n",
        "    return -2 * x * (y - model(x, M, C))\n",
        "\n",
        "# Derivative of the Squared Error with respect to C\n",
        "def dSE_dC(x, y, M, C):\n",
        "    return -2 * (y - model(x, M, C))\n",
        "\n",
        "# Gradient Descent function\n",
        "def gradient_descent(X, Y, learning_rate, max_iterations, initial_M, initial_C):\n",
        "    M, C = initial_M, initial_C\n",
        "    for _ in range(max_iterations):\n",
        "        for x, y in zip(X, Y):\n",
        "            M = M - learning_rate * dSE_dM(x, y, M, C)\n",
        "            C = C - learning_rate * dSE_dC(x, y, M, C)\n",
        "    return M, C\n",
        "\n",
        "# Sample data (X, Y)\n",
        "X = [1, 2, 3, 4]\n",
        "Y = [2, 4, 6, 8]\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.01\n",
        "max_iterations = 1000\n",
        "initial_M = 0.0\n",
        "initial_C = 0.0\n",
        "\n",
        "# Find the optimal values of M and C\n",
        "optimal_M, optimal_C = gradient_descent(X, Y, learning_rate, max_iterations, initial_M, initial_C)\n",
        "print(\"The optimal values of M and C are:\", optimal_M, optimal_C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SYXQ-d8Kss0",
        "outputId": "a611b0c8-caff-4f8a-9502-d21ad45a8bd8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The optimal values of M and C are: 1.9999998815747182 3.7962766099098773e-07\n"
          ]
        }
      ]
    }
  ]
}